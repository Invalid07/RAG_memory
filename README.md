# RAG_memory
Retrieval-Augmented Generation (RAG) framework with integrated memory support. It combines vector-based document retrieval with a memory module to maintain conversational context across multiple interactions. Built with modular components for embedding, retrieval, and generation

ğŸ”ğŸ’¬ Conversational RAG with Memory using LangChain + Google Gemini
This project integrates Retrieval-Augmented Generation (RAG) with memory to create smart, context-aware chat experiences. It uses:

ğŸ§  ChatGoogleGenerativeAI for powerful LLM responses
ğŸ§² GoogleGenerativeAIEmbeddings + FAISS for fast, semantic vector search
ğŸ§© RecursiveCharacterTextSplitter for clean chunking of large texts
ğŸ—‚ï¸ ConversationBufferMemory to retain past chat context
ğŸ”„ ConversationalRetrievalChain to tie everything together seamlessly

